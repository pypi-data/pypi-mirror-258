Metadata-Version: 2.1
Name: aimet-torch
Version: 1.30.1
Summary: AIMET torch Package
Home-page: https://quic.github.io/aimet-pages/index.html
Author: Qualcomm Innovation Center, Inc.
Author-email: aimet.os@quicinc.com
License: NOTICE.txt
Platform: x86
Requires-Python: >=3.8
Description-Content-Type: text/plain
Requires-Dist: cumm ==0.2.8
Requires-Dist: spconv ==2.1.20
Requires-Dist: torch ==1.13.1
Requires-Dist: torchvision ==0.14.1
Requires-Dist: matplotlib >=3
Requires-Dist: numpy <1.24,>=1.16.6
Requires-Dist: onnx ==1.14.1
Requires-Dist: onnxruntime ==1.15.1
Requires-Dist: onnxruntime-extensions
Requires-Dist: onnxsim
Requires-Dist: pandas ==1.5.3
Requires-Dist: protobuf ==3.20.2
Requires-Dist: psutil
Requires-Dist: tensorboardX ==2.4
Requires-Dist: transformers ==4.27.4
Requires-Dist: bokeh ==1.2.0
Requires-Dist: dataclasses
Requires-Dist: h5py ==2.10.0
Requires-Dist: holoviews ==1.12.7
Requires-Dist: hvplot ==0.4.0
Requires-Dist: Jinja2 ==3.0.3
Requires-Dist: jsonschema
Requires-Dist: osqp
Requires-Dist: progressbar2
Requires-Dist: pybind11
Requires-Dist: PyYAML
Requires-Dist: scikit-learn ==1.1.3
Requires-Dist: scipy ==1.8.1
Requires-Dist: setuptools
Requires-Dist: tqdm

#==============================================================================
#  @@-COPYRIGHT-START-@@
#
#  Copyright (c) 2021-2023, Qualcomm Innovation Center, Inc. All rights reserved.
#
#  SPDX-License-Identifier: BSD-3-Clause
#
#  @@-COPYRIGHT-END-@@
#==============================================================================

========
Overview
========
AI Model Efficiency Toolkit (AIMET) is a library that provides advanced model
quantization and model compression techniques for trained neural network
models. It provides features that have been proven to improve run-time
performance of deep learning neural network models with lower compute and
memory requirements and minimal impact to task accuracy.

Features
========
AIMET supports the following features

- Model Quantization
  - Quantization simulation: Simulates on-target quantized inference.
    Specifically simulates Qualcomm SnapDragon DSP accelerators.
  - Quantization-aware training: Fine-tune models to improve on-target
    quantized accuracy
  - Data Free quantization: Post-training technique to improve quantized
    accuracy by equalizing model weights (Cross-Layer Equalization) and
    correcting shifts in layer outputs due to quantization (Bias Correction)

- Model Compression
  - Spatial SVD: Tensor decomposition technique to split a large layer
    into two smaller ones
  - Channel Pruning: Removes redundant input channels of convolutional
    layers and modifies the model graph accordingly
  - Compression-ratio Selection: Automatically selects per-layer compression
    ratios

============
Dependencies
============
See the https://quic.github.io/aimet-pages/releases/latest/install/index.html for details.

=============
Documentation
=============
Please refer to the Documentation at https://quic.github.io/aimet-pages/index.html
for the user guide and API documentation.

=================
Using the Package
=================
Please see https://github.com/quic/aimet#getting-started for package requirements
and usage.


