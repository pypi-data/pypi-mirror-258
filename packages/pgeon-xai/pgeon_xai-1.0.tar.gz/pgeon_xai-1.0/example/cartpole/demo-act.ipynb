{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI In Action - pgeon\n",
    "\n",
    "This notebook shows the current functionalities of the **pgeon** library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Loading an environment, an agent and a discretizer; the necessary elements to generate a Policy Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:01.808105Z",
     "start_time": "2023-12-16T13:16:01.677121Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from example.cartpole.discretizer import CartpoleDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:01.808279Z",
     "start_time": "2023-12-16T13:16:01.681045Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:01.809694Z",
     "start_time": "2023-12-16T13:16:01.684061Z"
    }
   },
   "outputs": [],
   "source": [
    "environment = gym.make('CartPole-v1')\n",
    "discretizer = CartpoleDiscretizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:01.809761Z",
     "start_time": "2023-12-16T13:16:01.687384Z"
    }
   },
   "outputs": [],
   "source": [
    "from pgeon import Agent\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "\n",
    "class CartpoleAgent(Agent):\n",
    "    def __init__(self, path):\n",
    "        self.agent = Algorithm.from_checkpoint(path)\n",
    "\n",
    "    def act(self, state):\n",
    "        return self.agent.compute_single_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:04.204058Z",
     "start_time": "2023-12-16T13:16:01.690668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergio/repos/pgeon/venv/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/sergio/repos/pgeon/venv/lib/python3.8/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/sergio/repos/pgeon/venv/lib/python3.8/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/sergio/repos/pgeon/venv/lib/python3.8/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2023-12-16 07:16:04,192\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = CartpoleAgent('checkpoints/PPO_CartPole-v1_1acbb_00000_0_2023-12-05_19-28-36/checkpoint_000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:04.207971Z",
     "start_time": "2023-12-16T13:16:04.206384Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:04.210846Z",
     "start_time": "2023-12-16T13:16:04.208401Z"
    }
   },
   "outputs": [],
   "source": [
    "from pgeon import PolicyGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy Graphs are instantiated with an environment and a discretizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:04.214088Z",
     "start_time": "2023-12-16T13:16:04.213005Z"
    }
   },
   "outputs": [],
   "source": [
    "pg = PolicyGraph(environment, discretizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a Policy Graph with the `fit()` function, in this case generating 1000 episode trajectories from our agent. If the PG has been previously fit, one can choose to update the PG with new trajectories (instead of re-generating the PG) with `update=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.797463Z",
     "start_time": "2023-12-16T13:16:04.214999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PG...:   0%|          | 0/200 [00:00<?, ?it/s]\u001B[36m(RolloutWorker pid=95275)\u001B[0m 2023-12-16 07:16:04,156\tWARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.\n",
      "Fitting PG...: 100%|██████████| 200/200 [00:15<00:00, 12.84it/s]\n"
     ]
    }
   ],
   "source": [
    "pg = pg.fit(agent, num_episodes=200, update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.800834Z",
     "start_time": "2023-12-16T13:16:19.798728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 14\n",
      "Number of edges: 132\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {len(pg.nodes)}')\n",
    "print(f'Number of edges: {len(pg.edges)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ach node has information about a discretized state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.804110Z",
     "start_time": "2023-12-16T13:16:19.802039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT))\n",
      "  Times visited: 2557\n",
      "  p(s):          0.071\n"
     ]
    }
   ],
   "source": [
    "arbitrary_state = list(pg.nodes)[0]\n",
    "\n",
    "print(arbitrary_state)\n",
    "print(f'  Times visited: {pg.nodes[arbitrary_state][\"frequency\"]}')\n",
    "print(f'  p(s):          {pg.nodes[arbitrary_state][\"probability\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each edge has information about a transition between states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.806896Z",
     "start_time": "2023-12-16T13:16:19.804846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From:    (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT))\n",
      "Action:  1\n",
      "To:      (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT))\n",
      "  Times visited:      379\n",
      "  p(s_to,a | s_from): 0.148\n"
     ]
    }
   ],
   "source": [
    "arbitrary_edge = list(pg.edges)[0]\n",
    "\n",
    "print(f'From:    {arbitrary_edge[0]}')\n",
    "print(f'Action:  {arbitrary_edge[2]}')\n",
    "print(f'To:      {arbitrary_edge[1]}')\n",
    "print(f'  Times visited:      {pg[arbitrary_edge[0]][arbitrary_edge[1]][arbitrary_edge[2]][\"frequency\"]}')\n",
    "print(f'  p(s_to,a | s_from): {pg[arbitrary_edge[0]][arbitrary_edge[1]][arbitrary_edge[2]][\"probability\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PolicyGraph` object also stores the full discretized episode trajectories of the last fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.809779Z",
     "start_time": "2023-12-16T13:16:19.807815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pg._trajectories_of_last_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each trajectory is stored as a (state0, action0, state1, ..., stateN) tuple ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.877036Z",
     "start_time": "2023-12-16T13:16:19.815206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(LEFT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(LEFT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STUCK_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(STABILIZING_LEFT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 0,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT)),\n 1,\n (Position(MIDDLE), Velocity(RIGHT), Angle(FALLING_RIGHT))]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg._trajectories_of_last_fit[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and saving Policy Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle\n",
    "\n",
    "Saving as pickle lets you restore the full state of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:19.953838Z",
     "start_time": "2023-12-16T13:16:19.817976Z"
    }
   },
   "outputs": [],
   "source": [
    "pg.save('pickle', './ppo-cartpole.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.332717Z",
     "start_time": "2023-12-16T13:16:19.956713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:             14\n",
      "Number of edges:             132\n",
      "Num. of stored trajectories: 200\n"
     ]
    }
   ],
   "source": [
    "pg_pickle = PolicyGraph.from_pickle('./ppo-cartpole.pickle')\n",
    "\n",
    "print(f'Number of nodes:             {len(pg_pickle.nodes)}')\n",
    "print(f'Number of edges:             {len(pg_pickle.edges)}')\n",
    "print(f'Num. of stored trajectories: {len(pg._trajectories_of_last_fit)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "\n",
    "Saving as CSV creates three separated CSV files for node, edge and trajectory information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.332810Z",
     "start_time": "2023-12-16T13:16:20.331287Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.447738Z",
     "start_time": "2023-12-16T13:16:20.334781Z"
    }
   },
   "outputs": [],
   "source": [
    "pg.save('csv', ['./ppo-cartpole_nodes.csv', './ppo-cartpole_edges.csv', './ppo-cartpole_trajectories.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.450853Z",
     "start_time": "2023-12-16T13:16:20.448577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'value', 'p(s)', 'frequency']\n",
      "['0', 'Position(MIDDLE)&Velocity(LEFT)&Angle(STABILIZING_RIGHT)', '0.07128519654307221', '2557']\n",
      "['1', 'Position(MIDDLE)&Velocity(LEFT)&Angle(STABILIZING_LEFT)', '0.0051017563423473656', '183']\n",
      "['2', 'Position(MIDDLE)&Velocity(RIGHT)&Angle(STABILIZING_LEFT)', '0.22272093671591858', '7989']\n",
      "['3', 'Position(MIDDLE)&Velocity(LEFT)&Angle(FALLING_LEFT)', '0.0046835795929746305', '168']\n",
      "['4', 'Position(MIDDLE)&Velocity(RIGHT)&Angle(FALLING_RIGHT)', '0.20448843044326737', '7335']\n",
      "['5', 'Position(MIDDLE)&Velocity(LEFT)&Angle(STUCK_LEFT)', '0.020797323668804015', '746']\n",
      "['6', 'Position(MIDDLE)&Velocity(RIGHT)&Angle(STUCK_RIGHT)', '0.17056035684415946', '6118']\n",
      "['7', 'Position(MIDDLE)&Velocity(LEFT)&Angle(FALLING_RIGHT)', '0.12863116810705325', '4614']\n",
      "['8', 'Position(MIDDLE)&Velocity(LEFT)&Angle(STUCK_RIGHT)', '0.036297741845553386', '1302']\n"
     ]
    }
   ],
   "source": [
    "with open('ppo-cartpole_nodes.csv', 'r+') as f:\n",
    "    csv_r = csv.reader(f)\n",
    "    for i in range(10):\n",
    "        print(next(csv_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges and trajectories use the IDs of the nodes, from the corresponding node CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.453910Z",
     "start_time": "2023-12-16T13:16:20.451901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'to', 'action', 'p(s)', 'frequency']\n",
      "['0', '5', '1', '0.1482205709816191', '379']\n",
      "['0', '3', '1', '0.048494329292139225', '124']\n",
      "['0', '0', '0', '0.1603441533046539', '410']\n",
      "['0', '0', '1', '0.09777082518576456', '250']\n",
      "['0', '8', '1', '0.03363316386390301', '86']\n",
      "['0', '11', '1', '0.20375439968713335', '521']\n",
      "['0', '9', '1', '0.12084473992960501', '309']\n",
      "['0', '10', '1', '0.028549080954243255', '73']\n",
      "['0', '7', '1', '0.03989049667579194', '102']\n"
     ]
    }
   ],
   "source": [
    "with open('ppo-cartpole_edges.csv', 'r+') as f:\n",
    "    csv_r = csv.reader(f)\n",
    "    for i in range(10):\n",
    "        print(next(csv_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each trajectory is stored as a series of (state0, action0, state1, ..., stateN) lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:20.456784Z",
     "start_time": "2023-12-16T13:16:20.454890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '0', '0', '1', '5', '0', '0', '1', '3', '0', '0', '1', '3', '0', '0', '1', '3', '0', '0', '0', '0', '1', '5', '0', '0', '1', '5', '0', '0', '1', '5', '1', '3', '0', '5', '0', '0', '1', '5', '0', '0', '1', '8', '0', '7', '1', '8', '0', '7', '1', '8', '0', '7', '1', '8', '1', '1', '0', '8', '1', '1', '0', '8', '1', '1', '0', '7', '0', '7', '1', '7', '1', '1', '0', '7', '0', '7', '1', '7', '1', '1', '0', '7', '1', '8', '0', '7', '1', '8', '1', '2', '0', '8', '0', '7', '1', '8', '0', '7', '1', '8', '1', '2', '0', '8', '0', '7', '1', '8', '0', '7', '1', '8', '1', '2', '0', '7', '1', '2', '0', '7', '1', '2', '0', '7', '1', '6', '1', '2', '0', '6', '1', '2', '0', '6', '0', '7', '1', '6', '1', '2', '0', '6', '1', '2', '0', '6', '1', '2', '0', '4', '0', '7', '1', '4', '1', '2', '1', '2', '0', '2', '1', '2', '0', '6', '0', '4', '1', '6', '0', '4', '1', '6', '0', '4', '1', '6', '1', '2', '1', '2', '0', '2', '0', '6', '0', '4', '1', '6', '1', '2', '0', '6', '1', '2', '0', '6', '0', '4', '0', '7', '1', '4', '1', '4', '1', '2', '0', '4', '1', '2', '0', '4', '0', '4', '1', '4', '1', '6', '0', '4', '1', '6', '0', '4', '1', '6', '0', '4', '1', '6', '1', '2', '1', '2', '0', '2', '1', '2', '0', '6', '0', '4', '1', '6', '1', '2', '0', '6', '0', '4', '1', '6', '1', '2', '0', '4', '0', '4', '1', '4', '0', '4', '1', '4', '0', '4', '0', '4', '1', '4', '1', '4', '1', '4', '1', '2', '0', '4', '1', '6', '0', '4', '1', '6', '0', '4', '1', '4', '1', '2', '0', '4', '0', '4', '1', '4', '0', '4', '0', '4', '1', '4']\n"
     ]
    }
   ],
   "source": [
    "with open('ppo-cartpole_trajectories.csv', 'r+') as f:\n",
    "    csv_r = csv.reader(f)\n",
    "    for i in range(1):\n",
    "        print(next(csv_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of loading Policy Graphs from CSV files. When loading from nodes and edges, though, episode trajectories cannot be restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.106890Z",
     "start_time": "2023-12-16T13:16:20.457933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:             14\n",
      "Number of edges:             132\n",
      "Num. of stored trajectories: 200\n"
     ]
    }
   ],
   "source": [
    "pg_csv = PolicyGraph.from_nodes_and_trajectories('./ppo-cartpole_nodes.csv', './ppo-cartpole_trajectories.csv',\n",
    "                                          environment, discretizer)\n",
    "print(f'Number of nodes:             {len(pg_csv.nodes)}')\n",
    "print(f'Number of edges:             {len(pg_csv.edges)}')\n",
    "print(f'Num. of stored trajectories: {len(pg_csv._trajectories_of_last_fit)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.110024Z",
     "start_time": "2023-12-16T13:16:21.107090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:             14\n",
      "Number of edges:             132\n",
      "Num. of stored trajectories: 0\n"
     ]
    }
   ],
   "source": [
    "pg_csv = PolicyGraph.from_nodes_and_edges('./ppo-cartpole_nodes.csv', './ppo-cartpole_edges.csv',\n",
    "                                          environment, discretizer)\n",
    "print(f'Number of nodes:             {len(pg_csv.nodes)}')\n",
    "print(f'Number of edges:             {len(pg_csv.edges)}')\n",
    "print(f'Num. of stored trajectories: {len(pg_csv._trajectories_of_last_fit)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram\n",
    "\n",
    "PGs can also be exported to the [gram](https://neo4j.com/developer-blog/gram-a-data-graph-format/) format, allowing visualization using Neo4j. Episode trajectories cannot be stored in this format, though.\n",
    "\n",
    "PGs currently cannot be loaded from a Gram file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.116635Z",
     "start_time": "2023-12-16T13:16:21.110114Z"
    }
   },
   "outputs": [],
   "source": [
    "pg.save('gram', './ppo-cartpole.gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.278820Z",
     "start_time": "2023-12-16T13:16:21.117502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CREATE (s0:State {\r\n",
      "  uid: \"s0\",\r\n",
      "  value: \"Position(MIDDLE)&Velocity(LEFT)&Angle(STABILIZING_RIGHT)\",\r\n",
      "  probability: 0.07128519654307221, \r\n",
      "  frequency:2557\r\n",
      "});\r\n",
      "CREATE (s1:State {\r\n",
      "  uid: \"s1\",\r\n",
      "  value: \"Position(MIDDLE)&Velocity(LEFT)&Angle(STABILIZING_LEFT)\",\r\n"
     ]
    }
   ],
   "source": [
    "!head ./ppo-cartpole.gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.443983Z",
     "start_time": "2023-12-16T13:16:21.281355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s0:State) WHERE s0.uid = \"s0\" CREATE (s13)-[:a0 {probability:0.10526315789473684, frequency:22}]->(s0);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s4:State) WHERE s4.uid = \"s4\" CREATE (s13)-[:a0 {probability:0.028708133971291867, frequency:6}]->(s4);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s4:State) WHERE s4.uid = \"s4\" CREATE (s13)-[:a1 {probability:0.019138755980861243, frequency:4}]->(s4);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s13:State) WHERE s13.uid = \"s13\" CREATE (s13)-[:a0 {probability:0.023923444976076555, frequency:5}]->(s13);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s13:State) WHERE s13.uid = \"s13\" CREATE (s13)-[:a1 {probability:0.03827751196172249, frequency:8}]->(s13);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s6:State) WHERE s6.uid = \"s6\" CREATE (s13)-[:a1 {probability:0.08133971291866028, frequency:17}]->(s6);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s5:State) WHERE s5.uid = \"s5\" CREATE (s13)-[:a0 {probability:0.023923444976076555, frequency:5}]->(s5);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s11:State) WHERE s11.uid = \"s11\" CREATE (s13)-[:a0 {probability:0.14832535885167464, frequency:31}]->(s11);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s2:State) WHERE s2.uid = \"s2\" CREATE (s13)-[:a1 {probability:0.11483253588516747, frequency:24}]->(s2);\r\n",
      "MATCH (s13:State) WHERE s13.uid = \"s13\" MATCH (s12:State) WHERE s12.uid = \"s12\" CREATE (s13)-[:a0 {probability:0.023923444976076555, frequency:5}]->(s12);"
     ]
    }
   ],
   "source": [
    "!tail ./ppo-cartpole.gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PG-based policies\n",
    "\n",
    "Using the `PGBasedPolicy`, we can create policies that replicate an agent's behavior, based on their generated Policy Graph. These policies are subclasses of the `pgeon.Agent` class.\n",
    "\n",
    "The policy mode (greedy/stochastic) can be specified via the `PGBasedPolicyMode` enum. The behavior when encountering an unknown node (select random action/search nearest node in PG) can be specified via the `PGBasedPolicyNodeNotFoundMode` enum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.447372Z",
     "start_time": "2023-12-16T13:16:21.445399Z"
    }
   },
   "outputs": [],
   "source": [
    "from pgeon import PGBasedPolicy, PGBasedPolicyMode, PGBasedPolicyNodeNotFoundMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T13:16:21.452095Z",
     "start_time": "2023-12-16T13:16:21.450556Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = PGBasedPolicy(pg, mode=PGBasedPolicyMode.GREEDY,\n",
    "                       node_not_found_mode=PGBasedPolicyNodeNotFoundMode.RANDOM_UNIFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[75], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done \u001B[38;5;129;01mand\u001B[39;00m steps \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m     12\u001B[0m     action \u001B[38;5;241m=\u001B[39m policy\u001B[38;5;241m.\u001B[39mact(obs)\n\u001B[0;32m---> 13\u001B[0m     obs, _, _, _, done \u001B[38;5;241m=\u001B[39m \u001B[43menvironment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     state \u001B[38;5;241m=\u001B[39m policy\u001B[38;5;241m.\u001B[39mpg\u001B[38;5;241m.\u001B[39mdiscretizer\u001B[38;5;241m.\u001B[39mdiscretize(obs)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01min\u001B[39;00m list_states:\n",
      "File \u001B[0;32m~/repos/pgeon/venv/lib/python3.8/site-packages/gymnasium/wrappers/time_limit.py:57\u001B[0m, in \u001B[0;36mTimeLimit.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[1;32m     47\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     55\u001B[0m \n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m     observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_episode_steps:\n",
      "File \u001B[0;32m~/repos/pgeon/venv/lib/python3.8/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001B[0m, in \u001B[0;36mOrderEnforcing.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call env.step() before calling env.reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/pgeon/venv/lib/python3.8/site-packages/gymnasium/wrappers/env_checker.py:49\u001B[0m, in \u001B[0;36mPassiveEnvChecker.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m env_step_passive_checker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv, action)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/pgeon/venv/lib/python3.8/site-packages/gymnasium/envs/classic_control/cartpole.py:190\u001B[0m, in \u001B[0;36mCartPoleEnv.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m    187\u001B[0m     reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32), reward, terminated, \u001B[38;5;28;01mFalse\u001B[39;00m, {}\n",
      "File \u001B[0;32m~/repos/pgeon/venv/lib/python3.8/site-packages/gymnasium/envs/classic_control/cartpole.py:302\u001B[0m, in \u001B[0;36mCartPoleEnv.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    301\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mevent\u001B[38;5;241m.\u001B[39mpump()\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrender_fps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mflip()\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "environment = gym.make('CartPole-v1', render_mode='human')\n",
    "obs, _ = environment.reset()\n",
    "done = False\n",
    "done_orig = False\n",
    "steps = 0\n",
    "list_states = []\n",
    "while True:\n",
    "    all_states = []\n",
    "    while not done and steps < 200:\n",
    "        action = policy.act(obs)\n",
    "        obs, _, _, _, done = environment.step(action)\n",
    "        state = policy.pg.discretizer.discretize(obs)\n",
    "        if state in list_states:\n",
    "            all_states.append(list_states.index(state))\n",
    "        else:\n",
    "            list_states.append(state)\n",
    "        steps = steps + 1\n",
    "    with open(f'/tmp/all-states.txt', 'a') as f:\n",
    "        for state in all_states:\n",
    "            f.write(f's{state}\\n')\n",
    "            f.flush()\n",
    "    # print(f'Observed state:  {obs}')\n",
    "    # print(f'Discretization:  {policy.pg.discretizer.discretize(obs)}')\n",
    "    # print(f'Selected action: {action}')\n",
    "    steps = 0\n",
    "    obs, _ = environment.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T15:26:54.022677Z",
     "start_time": "2023-12-16T15:24:22.639227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-12-16T13:16:51.553734Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
