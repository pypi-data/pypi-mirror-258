Metadata-Version: 2.1
Name: rechat-eval
Version: 0.0.3
Summary: Tools for Evaluating Rechat LLMs
Home-page: https://github.com/parlance-labs/rechat-eval
Author: Hamel Husain
Author-email: hamel.husain@gmail.com
License: Apache Software License 2.0
Keywords: nbdev jupyter notebook python
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyairtable
Requires-Dist: langfree >=0.0.29
Provides-Extra: dev

# rechat-eval


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

[![](https://github.com/parlance-labs/rechat-eval/actions/workflows/test.yaml/badge.svg)](https://github.com/parlance-labs/rechat-eval/actions/workflows/test.yaml)

Utilities that help with:

- Data extraction
- Annotation, review and evaluation
- Visualization

These tools are very specific to [Rechat](https://rechat.com/), and may
not generalize to other situations.

## Install

The python library is located on this private repo on GitHub
[parlance-labs/rechat-eval](https://github.com/parlance-labs/rechat-eval.git)

``` sh
pip install git+https://github.com/parlance-labs/rechat-eval.git
```

# Docs

Clone this repo and run

    cd _docs && python -m http.server

You will see the site at <http://localhost:8000/>. We arenâ€™t hosting the
site on GitHub Pages because this site is private.

## Usage
