# Qleverfile for Wikidata, use with https://github.com/ad-freiburg/qlever-control
#
# qlever get-data    downloads two .bz2 files of total size ~100 GB
# qlever index       takes ~7 hours and ~40 GB RAM (on an AMD Ryzen 9 5900X)
# qlever start       starts the server (takes around 30 seconds)

[data]
NAME              = wikidata
GET_DATA_URL      = https://dumps.wikimedia.org/wikidatawiki/entities
GET_DATA_CMD      = curl -LO -C - ${GET_DATA_URL}/latest-all.ttl.bz2 ${GET_DATA_URL}/latest-lexemes.ttl.bz2
INDEX_DESCRIPTION = "Full Wikidata dump from ${GET_DATA_URL} (latest-all.ttl.bz2 and latest-lexemes.ttl.bz2)"

[index]
FILE_NAMES      = latest-lexemes.ttl.bz2 latest-all.ttl.bz2 
CAT_FILES       = bzcat ${FILE_NAMES}
SETTINGS_JSON   = { "languages-internal": ["en"], "prefixes-external": [ "<http://www.wikidata.org/entity/statement", "<http://www.wikidata.org/value", "<http://www.wikidata.org/reference" ], "locale": { "language": "en", "country": "US", "ignore-punctuation": true }, "ascii-prefixes-only": false, "num-triples-per-batch": 5000000 }
WITH_TEXT_INDEX = false
STXXL_MEMORY    = 10g

[server]
PORT                  = 7001
ACCESS_TOKEN          = ${data:NAME}_372483264
MEMORY_FOR_QUERIES    = 50G
CACHE_MAX_SIZE        = 30G

[docker]
USE_DOCKER = true
IMAGE      = adfreiburg/qlever

[ui]
PORT   = 7000
CONFIG = wikidata
