Metadata-Version: 2.1
Name: intent-pilot
Version: 0.1.0
Summary: what can be said can be automated
Author-Email: gitlost-murali-askui <murali.kondragunta@askui.com>
License: MIT
Requires-Python: >=3.9
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: Pillow>=10.2.0
Requires-Dist: requests>=2.31.0
Requires-Dist: openai>=1.12.0
Requires-Dist: PyAutoGUI>=0.9.54
Requires-Dist: plyer>=2.1.0
Requires-Dist: prompt-toolkit>=3.0.43
Requires-Dist: fuzzywuzzy[speedup]>=0.18.0
Requires-Dist: pyperclip>=1.8.2
Description-Content-Type: text/markdown


<h1 align="center">⧐ Intent Pilot </h1>

What can be said can be automated

<p align="center">
    <a href="https://discord.com/invite/Gu35zMGxbx">
        <img alt="Discord" src="https://img.shields.io/discord/912752657662349312
        ?logo=discord&style=flat&logoColor=white"/></a>
    <img src="https://img.shields.io/static/v1?label=license&message=MIT&color=white&style=flat" alt="License"/>
    <br>
    <br>
    <strong>What can be said can be automated.</strong><br>
    <br><a href="https://askui.com">Get early access to the PTA model</a>‎ ‎ |‎ ‎ <a href="https://askui.com/">Scale on our shoulders</a><br>
</p>

<br>

**Intent Pilot** 

Intent-Pilot is an orchestration of two tools: AskUI's object detector with OpenAI's GPT-4v to achieve automation. It is designed to automate repetitive tasks, and to assist users in performing complex tasks with ease.

<br>

## Demo

--video-here


## Quick Start

```shell
pip install intent-pilot
```

### Terminal

After installation, simply run `intent` in your terminal:

```shell
intent
```

In case, you are unable to run the command, try installing the following dependencies for linux platforms:
```shell
sudo apt-get install python3-tk python3-dev
```

# Contributing

Thank you for your interest in contributing! We welcome involvement from the community.

Please see our [contributing guidelines](docs/CONTRIBUTING.md) for more details on how to get involved.

# Roadmap

We are currently in the process of building PTA (Prompt-to-automation) model, a vision+language model that can understand and execute commands in natural language, in real-time and faster than any VPA (Virtual Personal Assistant) in the market.